{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==== Import libs ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- utils libs ----\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from typing import Optional\n",
    "\n",
    "# --- Import functions from utils.py ---\n",
    "import sys\n",
    "sys.path.insert(0,'../src')\n",
    "\n",
    "from utils import plot_confusion_matrix, plot_activity_hist, load_dataset, load_aggregate_dataset, time_in_range, segmentDf, create_sequence, train_test_split_dataset, convertToSequenceParameters\n",
    "\n",
    "# ---- Data Viz libs ---- \n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import hiplot as hip\n",
    "\n",
    "# ---- ML libs ----\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ---- Deep Learning libs ----\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "### Optimizer hyperparameters model ###\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "####  1/ Load the dataset and resample timeseries\n",
    "####  2/ Split a dataframe into train set and test set according to the split rate\n",
    "####  3/ Standardize Data\n",
    "####  4/ Construction of the dataset according to peak and off-peak hours or according to activity labels\n",
    "####  5/ Creation of sequences of length T and according to the overlapping period\n",
    "\n",
    "Return preprocessed ``3D-array`` ``[samples, SEQUENCE_LENGTH, features]`` (i.e sequences from the timeseries) , as required for **LSTM** network. We want our network to have memory of **10 days**, so we set ``SEQUENCE_LENGTH=10``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(timeframes: list\n",
    "                  ,sequence_length: int\n",
    "                  , overlap_period: int\n",
    "                  ,resample_period :Optional[str]=None\n",
    "                  ,use_labels :Optional[bool]=False\n",
    "                  ,strategy :Optional[str] = \"off_peak_time\" \n",
    "                  ,split_rate :Optional[float]=0.2\n",
    "                  , split_method=None) -> np.array:\n",
    "    \"\"\"\n",
    "    1/ Loads the dataset and resample timeseries\n",
    "    2/ Split a dataframe into train set and test set according to the split rate\n",
    "    3/ Standardize Data\n",
    "    4/ Construction of the dataset according to peak and off-peak hours \n",
    "    or according to activity labels\n",
    "    5/ Creation of sequences of length T and according to the overlapping period\n",
    "    \n",
    "    Args:\n",
    "        - resample_period: (optional) the reasmple period, if None the default period of 1 second will be used\n",
    "        - timeframes: list of tuples indicating the periods of the day ex: timeframes = [(datetime.time(10,0,0), datetime.time(6,0,0)), (datetime.time(12,0,0), datetime.time(13,0,0))\n",
    "        - use_labels: (False by default) use the activities labels\n",
    "        - sequence_length: length of the sequence\n",
    "        - overlap_period: overlap the sequences of timeseries\n",
    "        - device_approach: the aggregated load curve of the devices which, when in operation, do not allow us to predict an activity \n",
    "        - split_rate: Rate of the test set size\n",
    "        - device_strategy: use inactive devices base load curve\n",
    "    Returns: \n",
    "        - list of prepocessed 3D-array [samples, sequence_length, features] (i.e sequences from the timeseries) \n",
    "    \"\"\"\n",
    "    \n",
    "    # Diplay preprocessing parameters\n",
    "    print(\"\\n---- Post Processing Parameters ----\")\n",
    "    print(\"TIMEFRAMES = \", timeframes)\n",
    "    print(\"SEQUENCE_LENGTH = \", sequence_length)\n",
    "    print(\"RESAMPLE_PERIOD = \", resample_period)\n",
    "    print(\"OVERLAP_PERIOD = \", overlap_period)\n",
    "    print(\"STRATEGY = \", strategy)\n",
    "        \n",
    "    # load dataset with labels and resampled timeseries\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"#### Loading and Resampling Data... ####\")\n",
    "    print(\"\")\n",
    "    df_resampled = load_dataset(\"house1_power_blk2_labels.zip\", resample_period)\n",
    "    \n",
    "    print(\"#### Creating Train and Test set... ####\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    # split dataframe into train set and test set\n",
    "    train_df, test_df, mask_test = train_test_split_dataset(df_resampled, method=split_method, split_rate=split_rate)\n",
    "    \n",
    "    # Standardize Data\n",
    "    print(\"#### Rescaling Data... ####\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    scaler = StandardScaler()\n",
    "    scaler_train = scaler.fit(train_df.loc[:, ['mains']])\n",
    "    \n",
    "    train_df.loc[:, 'mains'] = scaler_train.transform(train_df.loc[:, ['mains']])\n",
    "    test_df.loc[:, 'mains'] = scaler_train.transform(test_df.loc[:, ['mains']])\n",
    "        \n",
    "    # ---- TEST SEQUENCES ----\n",
    "    print(\"#### Creating Test Sequence... ####\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    if split_method==\"random_days\":\n",
    "        list_df_test = []\n",
    "        mask = ((mask_test) != (np.roll(mask_test, 1)))[mask_test]\n",
    "        a = np.where(mask)[0]\n",
    "        if 0 in a and len(a>1):\n",
    "            a = a[1:]\n",
    "        for df in np.split(test_df, a):\n",
    "            list_df_test.append(df)\n",
    "        # init 3D-array [samples, sequence_length, features]\n",
    "        first_df_test = list_df_test[0]\n",
    "        X_sequences_test, y_sequences_test = create_sequence(first_df_test, sequence_length, overlap_period)\n",
    "        list_df_test.pop(0) # delete the first element of the list of train dataframes\n",
    "\n",
    "        # Creation of sequences of length T and according to the overlapping period\n",
    "        for df_test_ in list_df_test:\n",
    "            next_X_sequences_test, next_y_sequences_test = create_sequence(df_test_, sequence_length, overlap_period)\n",
    "            X_sequences_test = np.append(X_sequences_test, next_X_sequences_test, axis = 0)\n",
    "            y_sequences_test = np.append(y_sequences_test, next_y_sequences_test, axis = 0)\n",
    "    else:\n",
    "        X_sequences_test, y_sequences_test = create_sequence(test_df, sequence_length, overlap_period)\n",
    "    \n",
    "    if strategy == \"off_peak_time\":\n",
    "        print(\"Strategy chosen : \", strategy)\n",
    "        print(\"\")\n",
    "        print(\"#### Creating Train Sequence... ####\")\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        # --- TRAIN SEQUENCES ----\n",
    "        # Construction of the dataset according to peak and off-peak hours \n",
    "        if split_method==\"random_days\":\n",
    "            list_df_train = []\n",
    "            mask = ((~mask_test) != (np.roll(~mask_test, 1)))[~mask_test]\n",
    "            for df in np.split(train_df, np.where(mask)[0]):\n",
    "                list_df_train.extend(segmentDf(df, timeframes = timeframes))\n",
    "        else:\n",
    "            list_df_train = segmentDf(train_df, timeframes = timeframes)\n",
    "\n",
    "        # init 3D-array [samples, sequence_length, features]\n",
    "        first_df_train = list_df_train[0]\n",
    "        list_X_sequence_train, list_y_sequence_train = create_sequence(first_df_train, sequence_length, overlap_period)\n",
    "        list_df_train.pop(0) # delete the first element of the list of train dataframes\n",
    "\n",
    "        # Creation of sequences of length T and according to the overlapping period\n",
    "        for df_train_ in list_df_train:\n",
    "            X_sequences_train, y_sequences_train = create_sequence(df_train_, sequence_length, overlap_period)\n",
    "            list_X_sequence_train = np.append(list_X_sequence_train, X_sequences_train, axis = 0)\n",
    "            list_y_sequence_train = np.append(list_y_sequence_train, y_sequences_train, axis = 0)\n",
    "        \n",
    "        print(\"---- X_train sequence shape ----\")\n",
    "        print(list_X_sequence_train.shape)\n",
    "\n",
    "        print(\"\\n---- y_train sequence shape ----\")\n",
    "        print(list_y_sequence_train.shape)\n",
    "\n",
    "        print(\"\\n\\n---- X_test sequence shape ----\")\n",
    "        print(X_sequences_test.shape)\n",
    "\n",
    "        print(\"\\n---- y_test sequence shape ----\")\n",
    "        print(y_sequences_test.shape)\n",
    "        \n",
    "        return train_df, test_df, list_X_sequence_train, list_y_sequence_train, X_sequences_test, y_sequences_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a custom architecture of an auto-encoder convolutional model\n",
    "\n",
    "We will build a convolutional reconstruction autoencoder model. The model will take input of shape (``batch_size``, ``sequence_length``, ``num_features``) and return output of the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build custom metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appel de la fonction d'évaluation qui retourne un score (ex AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    params = {'n_estimators' : trial.suggest_int('n_estimators', 1, 5),\n",
    "              'criterion' : trial.suggest_categorical('criterion', [\"gini\", \"entropy\"]),\n",
    "             }\n",
    "    \n",
    "    RF_model = RandomForestClassifier(**params)\n",
    "    \n",
    "    RF_model.fit(X_train_RF, y_train_RF)\n",
    "    \n",
    "    y_pred = RF_model.predict(X_valid_RF)\n",
    "    \n",
    "    score = custom_metric(y_valid_RF, y_pred, X_valid_RF)\n",
    "    return score\n",
    "\n",
    "\n",
    "# boucler le fine-tuning optuna sur différents dataset de preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune hyperpamarameters with ``optuna``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#study = optuna.create_study(direction = \"maximize\")\n",
    "#study.optimize(objective, n_trials = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show result into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show optuna results\n",
    "\n",
    "#study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merger le dataframe avec les différents hyperparamètre utilisé pour\n",
    "# le preprocessing avec le dataframe (i.e output) généré par optuna "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analize the impact of hyperparameter on the custom metric with ``HiPlot``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_hiplot = hip.Experiment.from_dataframe(result_df)\n",
    "# result_hiplot.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
